{
  "hash": "0628aeecce17496cd317e5c60b1ec81d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Analysis\ndescription: Here we provide a detailed analysis using more sophisticated statistics techniques.\ntoc: true\ndraft: false\n---\n\n\n\n\n![](https://upload.wikimedia.org/wikipedia/commons/7/77/Pebbleswithquarzite.jpg)\n\nThis comes from the file `analysis.qmd`.\n\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You'll also reflect on next steps and further analysis.\n\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc. \n\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points.\nIf you want you can link back to your blog posts or create separate pages with more details.\n\nThe style of this paper should aim to be that of an academic paper. \nI don't expect this to be of publication quality but you should keep that aim in mind.\nAvoid using \"we\" too frequently, for example \"We also found that ...\". Describe your methodology and your findings but don't describe your whole process.\n\n### Example of loading data\n\nThe code below shows an example of loading the loan refusal data set (which you should delete at some point).\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nhere() starts at /Users/zzzhao/Desktop/MA415/ma-4615-fa24-final-project-group-4\n\nLoading required package: viridisLite\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\nGetting data from the 2016-2020 5-year ACS\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](analysis_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Note on Attribution\n\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don't have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don't need a formal citation.\n\nIf you are directly quoting from a source, please make that clear. You can show quotes using `>` like this\n\n```         \n> To be or not to be.\n```\n\n> To be or not to be.\n\n------------------------------------------------------------------------\n\n## Rubric: On this page\n\nYou will\n\n-   Introduce what motivates your Data Analysis (DA)\n    -   Which variables and relationships are you most interested in?\n    -   What questions are you interested in answering?\n    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n-   Modeling and Inference\n    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\n    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\n    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n-   Explain the flaws and limitations of your analysis\n    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n-   Clarity Figures\n    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\n    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\n    -   Default `lm` output and plots are typically not acceptable.\n-   Clarity of Explanations\n    -   How well do you explain each figure/result?\n    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n-   Organization and cleanliness.\n    -   Make sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\n    -   This page should be self-contained, i.e. provide a description of the relevant data.\n    \n    \n    \n# What Motivated Our Data Analysis:\nCrime is a pervasive issue that affects communities differently based on various socioeconomic, demographic, and geographic factors. Understanding what drives crime frequency is crucial for developing effective policies and interventions to promote equity and public safety.\n\nOur data analysis was motivated by the desire to uncover relationships between crime and the following key factors:\n\n**Economic Status** (e.g., median income) \\\n**Demographics** (e.g., racial composition) \\\n**Location** (e.g., neighborhood characteristics) \\\n\\\n\n\n\n# Variables of Interest\n\nThe primary variables we analyzed included:\n\n**Crime Frequency:** The total number of reported crimes in a neighborhood. \\\n**Economic Data:** Median household income from the American Community Survey (ACS). \\\n**Neighborhood Boundaries:** Spatial boundaries defined by the LA Times. \\\n**Location Data:** Geospatial coordinates (latitude and longitude) for reported crime incidents. \\\n#Add to here as necessary \\\nTo explore these variables, we integrated datasets from LAPD crime reports, U.S. Census economic data, and geospatial shapefiles for Los Angeles neighborhoods. This allowed us to analyze both spatial and statistical relationships. \\\n#Add links here\n\n# Key Questions\n**Economic Status and Crime:** Does a neighborhood's median income influence the number of crimes reported? \\\n**Geographic Crime Hotspots:** Are there specific areas with persistently high crime rates? \\\n**Disparities in Crime Impact:** How do demographic or socioeconomic disparities correlate with crime?\n#Add here as necessary \\\n\n# Modeling Economic Data\nFor a specific statistic model when looking at the economic data in relation to crime, we used a negative binomial relaationship. Initially, we were recommended to utilize a poisson distribution but because there was a statistically significant difference between mean and variance. So, we felt as if a negative binomial was fitting for this problem. \n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'MASS'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = total_crimes ~ avg_income, data = crime_summary_lapd, \n    init.theta = 2.288655763, link = log)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  1.924e+00  3.495e-02  55.062   <2e-16 ***\navg_income  -4.169e-06  4.179e-07  -9.977   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2887) family taken to be 1)\n\n    Null deviance: 2336.5  on 2296  degrees of freedom\nResidual deviance: 2233.8  on 2295  degrees of freedom\nAIC: 11983\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.2887 \n          Std. Err.:  0.0926 \n\n 2 x log-likelihood:  -11977.1990 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## 1. Coefficients\n\n### Intercept:\n- **Estimate**: 1.924 \\\n- **Exponentiated**: ~ 6.85 \\\n  - This means that when the median income is zero (a hypothetical reference), the expected number of crimes is about 6.85 crimes per area.\n\n### Avg_Income Coefficient:\n- **Estimate**: -4.169 \\times 10^{-6}\n- **Exponentiated**: ~0.9999958 \\\n  - For every $1 increase in median income, the expected crime count decreases by approximately \\(0.00042\\%\\).  \n  - For a more interpretable unit, for every $10,000 increase in median income, the expected crime count decreases by approximately 4.2\\%.\n\n### Significance:\n- **z-value**: -9.977\n- **p-value**: p < 2 \\times 10^{-16} \n  - The negative relationship between income and crime is highly statistically significant.\n\n---\n\n## 2. Model Fit\n\n### Null Deviance:\n- **Value**: 2336.5\n  - This represents the deviance of a null model with no predictors.\n\n### Residual Deviance:\n- **Value**: 2233.8\n  - The reduction from the null deviance indicates an improvement in model fit.\n\n---\n\n## 3. Dispersion Parameter :\n- **Value** = 2.2887, with a standard error of 0.0926.\n  - A higher value indicates better accommodation of variance in the data. (This was previously tested using Poisson distributed prior and this was a lower theta-value)\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](analysis_files/figure-html/Neg Bin Chart-1.png){width=672}\n:::\n:::\n\n\n\nThe chart shown supports the summary above where we said that as median income increases, crime numbers seem to decrease. Even though it isn't by much, it does trend slightly downward. \n\n\n## 4. Coefficient Estimates and Their Standard Errors\n**Standard Error (SE):** Measures the variability of each coefficient estimate. Smaller SE indicates more precise estimates. For example:\n\nThe SE for the intercept is *0.03495*.\nThe SE for the median income coefficient is 4.179 \\times 10^{-7}.\n\n## 5. Confidence Intervals\nCalculated as:\n\n\nEstimate: 1.96 * Standard Error \\\n\n\n- For the **avg_income coefficient**:\n  \\[\n  -4.169 * 10^{-6},  1.96 * 4.179 * 10^{-7}\n  \\]\n  - Confidence Interval: [-4.42 * 10^{-6}, -3.91 * 10^{-6}]\n\n- **Interpretation**: The true effect of median income on crime likely lies within this range. It reinforces the negative relationship but highlights uncertainty in its exact magnitude.\n\n## 6. Conclusions about Economic Data\n\n\n\n\n",
    "supporting": [
      "analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}