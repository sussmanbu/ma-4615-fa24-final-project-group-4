---
title: "Big Picture"
description: "A 538/Upshot style article about the data."
toc: true
draft: false
format:
  html:
    resources:
      - shinylive-sw.js
filters:
  - shinylive
---
```{r load libraries}
#| results: "hide"
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(sf)
library(tidycensus)
library(here)
library(viridis)
library(dplyr)
library(MASS)
library(tidyr)

# Load crime data and convert to spatial format
data <- readRDS(here("filtered_data_2.rds"))
crime_sf <- st_as_sf(data, coords = c("LON", "LAT"), crs = 4326)

# Load neighborhood boundaries
neighborhoods <- st_read(here("LA_Times_Neighborhood_Boundaries-shp/8494cd42-db48-4af1-a215-a2c8f61e96a22020328-1-621do0.x5yiu.shp")) %>%
  st_transform(st_crs(crime_sf))

# Join crime incidents with neighborhoods
crime_with_neighborhoods <- st_join(crime_sf, neighborhoods, join = st_within)
census_api_key("c2aebe6041f0c99e41a3458ed8d0b95ee3650fa4")

# Load and transform median income data
economic_data <- get_acs(
  geography = "block group",
  variables = c(median_income = "B19013_001"),
  state = "CA",
  county = "Los Angeles",
  year = 2020,
  geometry = TRUE
) %>% 
  st_transform(st_crs(crime_with_neighborhoods))

# Join income with neighborhood-level crime data
crime_with_income <- st_join(crime_with_neighborhoods, economic_data, join = st_within)

# Summarize crime data by neighborhood
crime_summary <- crime_with_income %>%
  group_by(GEOID) %>%
  summarize(
    total_crimes = n(),
    avg_income = mean(estimate, na.rm = TRUE),
    geometry = st_union(geometry)
  ) %>%
  filter(!is.na(avg_income)) %>%  # Remove rows with missing income
  st_as_sf()



lapd_boundary <- st_read(here("CityBoundaryofLosAngeles/geo_export_416eaeda-447a-4473-b003-37e2cad181ac.shp")) %>%
  st_transform(st_crs(crime_sf))  # Align CRS



crime_within_lapd <- crime_sf %>%
  filter(rowSums(st_within(geometry, st_geometry(lapd_boundary), sparse = FALSE)) > 0)

crime_with_income_lapd <- st_join(crime_within_lapd, economic_data, join = st_within)

economic_data_lapd <- st_intersection(economic_data, lapd_boundary)


# Update the crime summary
crime_summary_lapd <- crime_with_income_lapd %>%
  group_by(GEOID) %>%
  summarize(
    total_crimes = n(),
    avg_income = mean(estimate, na.rm = TRUE),
    geometry = st_union(geometry)
  ) %>%
  filter(!is.na(avg_income)) %>%  # Exclude rows with missing income
  st_as_sf()

crime_summary_race <- crime_with_income %>%
  group_by(GEOID, Descent_Description) %>%
  summarize(
    total_crimes = n(),  # Count crimes for each GEOID and Descent_Description group
    avg_median_income = mean(estimate, na.rm = TRUE)
  ) %>%
  pivot_wider(
    names_from = Descent_Description,
    values_from = total_crimes,
    values_fill = 0  # Fill missing values with 0 for crimes
  ) %>%
  rowwise() %>%
  mutate(
    total_crimes = sum(c_across(-c(GEOID, avg_median_income, geometry)), na.rm = TRUE)  # Sum only the crime columns
  ) %>%
  ungroup()

crime_summary_race <- crime_summary_race %>%
  rename_with(~ make.names(.), everything())

crime_summary_race_model <- crime_summary_race %>%
  filter(complete.cases(
    avg_median_income, Hispanic.Latin.Mexican, White, Black, Other, Other.Asian,
    Unknown, Japanese, Korean, Filipino, Chinese, Hawaiian, Asian.Indian,
    American.Indian.Alaskan.Native, Cambodian, Vietnamese, Laotian
  ))


bivar_nb_model <- glm.nb(total_crimes ~ avg_median_income + Hispanic.Latin.Mexican + White + Black + Other + 
    Other.Asian + Unknown + Japanese + Korean + Filipino + Chinese + Hawaiian + 
    Asian.Indian + American.Indian.Alaskan.Native + Cambodian + Vietnamese + Laotian, data = crime_summary_race)

# Add predicted values to the filtered data
crime_summary_race_model <- crime_summary_race_model %>%
  mutate(predicted_crimes = predict(bivar_nb_model, type = "response"))

crime_race_long <- crime_summary_race_model %>%
  pivot_longer(
    cols = c(Hispanic.Latin.Mexican, White, Black, Other, Other.Asian, Unknown, 
             Japanese, Korean, Filipino, Chinese, Hawaiian, Asian.Indian, 
             American.Indian.Alaskan.Native, Cambodian, Vietnamese, Laotian),
    names_to = "race",
    values_to = "crime_count"
  )


crime_race_long <- crime_summary_race %>%
  pivot_longer(
    cols = c(Hispanic.Latin.Mexican, White, Black, Other, Other.Asian, Unknown, 
             Japanese, Korean, Filipino, Chinese, Hawaiian, Asian.Indian, 
             American.Indian.Alaskan.Native, Cambodian, Vietnamese, Laotian),
    names_to = "race",
    values_to = "crime_count"
  ) %>%
  filter(!is.na(crime_count) & crime_count > 0) %>%
  mutate(avg_median_income = avg_median_income / 1000)



# Fit Poisson regression with pivoted data
poisson_model <- glm(
  crime_count ~ avg_median_income + race,
  family = poisson(link = "log"),
  data = crime_race_long
)
summary(poisson_model)

# Fit Negative Binomial regression with pivoted data
crime_race_long <- crime_race_long %>%
  filter(complete.cases(avg_median_income, race, crime_count))

nb_model <- glm.nb(
  crime_count ~ avg_median_income * race,
  data = crime_race_long
)

crime_race_long <- crime_race_long %>%
  mutate(predicted_crimes = predict(nb_model, newdata = crime_race_long, type = "response"))


lapd_boundary <- st_read(here("CityBoundaryofLosAngeles/geo_export_416eaeda-447a-4473-b003-37e2cad181ac.shp")) %>%
  st_make_valid() %>%                # Ensure valid geometry
  st_transform(crs = 4326)           # Align CRS (use WGS84 as default)

# Load neighborhoods
neighborhoods <- st_read(here("LA_Times_Neighborhood_Boundaries-shp/8494cd42-db48-4af1-a215-a2c8f61e96a22020328-1-621do0.x5yiu.shp")) %>%
  st_make_valid() %>%
  st_transform(crs = st_crs(lapd_boundary))  # Match CRS with LAPD boundary


lapd_boundary <- st_read(here("CityBoundaryofLosAngeles/geo_export_416eaeda-447a-4473-b003-37e2cad181ac.shp")) %>%
  st_make_valid() %>%                # Ensure valid geometry
  st_transform(crs = 4326)           # Align CRS (use WGS84 as default)

# Load neighborhoods
neighborhoods <- st_read(here("LA_Times_Neighborhood_Boundaries-shp/8494cd42-db48-4af1-a215-a2c8f61e96a22020328-1-621do0.x5yiu.shp")) %>%
  st_make_valid() %>%
  st_transform(crs = st_crs(lapd_boundary))  # Match CRS with LAPD boundary


population_data <- get_acs(
  geography = "block group",
  variables = c(total_population = "B01003_001"),
  state = "CA",
  county = "Los Angeles",
  year = 2020,
  geometry = TRUE
)

neighborhoods <- st_read(here("LA_Times_Neighborhood_Boundaries-shp/8494cd42-db48-4af1-a215-a2c8f61e96a22020328-1-621do0.x5yiu.shp")) %>%
  st_make_valid() %>%
  st_transform(st_crs(population_data))


population_with_neighborhoods <- st_join(population_data, neighborhoods, join = st_within)


# Summarize total population by neighborhood
neighborhood_population <- population_with_neighborhoods %>%
  group_by(name) %>%  # Assuming 'name' is the neighborhood name column
  summarize(total_population = sum(estimate, na.rm = TRUE)) %>%
  filter(!is.na(total_population))  # Exclude rows with missing population


areaData <- readRDS(here("crime_counts_by_area_with_coords.rds"))

# Convert crime data into a spatial object (assuming coordinates are in 'avg_longitude' and 'avg_latitude')
crime_data_sf <- st_as_sf(areaData, coords = c("avg_longitude", "avg_latitude"), crs = 4326)

# Ensure that the neighborhood population data and neighborhoods are in the same CRS
neighborhood_population <- st_transform(neighborhood_population, st_crs(crime_data_sf))
neighborhoods <- st_transform(neighborhoods, st_crs(crime_data_sf))

# Ensure both datasets have valid geometries
crime_data_sf <- st_make_valid(crime_data_sf)
neighborhood_population <- st_make_valid(neighborhood_population)

# Check the CRS of both datasets to ensure they match
print(st_crs(crime_data_sf))  # CRS of crime data
print(st_crs(neighborhood_population))  # CRS of neighborhood population

# If necessary, transform the neighborhood population data to the same CRS as crime data
# This step should be redundant if CRS checks show they already match
neighborhood_population <- st_transform(neighborhood_population, st_crs(crime_data_sf))

# Perform the spatial join to associate crime data with the neighborhood polygons
crime_population_with_data <- st_join(crime_data_sf, neighborhood_population, join = st_within)

# Now calculate the crime-to-population ratio for each record
crime_population_summary <- crime_population_with_data %>%
  mutate(crime_to_population_ratio = crime_count / total_population)  # Divide total crime by total population




```

```{shinylive-r}
#| results: "hide"
#| echo: false
#| standalone: true
#| viewerHeight: 640
library(tidyverse)
library(sf)
library(tidycensus)
library(here)
library(viridis)
library(dplyr)
library(MASS)
library(tidyr)
library(shiny)

options("readr.edition" = 1)
crime_with_income_lapd <- read_rds("https://sussmanbu.github.io/ma-4615-fa24-final-project-group-4/shiny_dataset/crime_with_income_lapd.rds")
economic_data_lapd<-read_rds("https://sussmanbu.github.io/ma-4615-fa24-final-project-group-4/shiny_dataset/economic_data_lapd.rds")

ui <- fluidPage(
  titlePanel("Crime and Economic Data in LAPD Jurisdiction"),
  sidebarLayout(
    sidebarPanel(
      sliderInput(
        inputId = "year",
        label = "Select Year:",
        min = 2020, 
        max = 2024, 
        value = 2020,
        step = 1
      )
    ),
    mainPanel(
      plotOutput("crimePlot")
    )
  )
)

server <- function(input, output, session) {
  output$crimePlot <- renderPlot({
    crime_filtered <- crime_with_income_lapd %>%
      filter(year == input$year)
    
    ggplot() +
      geom_sf(data = economic_data_lapd, aes(fill = estimate), color = NA) +  
      scale_fill_viridis_c(option = "magma", na.value = "grey50") +
      geom_sf(data = crime_filtered, color = "black", shape = 4, size = 0.5, alpha = 0.7) +
      labs(
        title = paste("Median Income and", input$year, "Crime Data within LAPD Jurisdiction"),
        fill = "Median Income"
      ) +
      theme_minimal() +
      coord_sf(xlim = c(-118.7, -118), ylim = c(33.7, 34.5),expand = FALSE)
  })
}

shinyApp(ui = ui, server = server)
```


## Beyond the Poverty Myth: Unraveling Los Angeles' Crime Landscape


When you think about crime, you might picture dangerous streets in low-income neighborhoods and pristine, secure communities in wealthier areas. Normally, you would avoid that one sketchy neighborhood when it is late at night. It’s a common narrative, repeated so often that it feels like fact: crime is a symptom of poverty, and wealth provides a safety net against it. But is this common perception really the truth?

Using the LAPD crime reports and Census data from the past 4 years, we set out to explore the connection between income levels and crime rates across different neighborhoods in Los Angeles. The results might surprise you. While crime does concentrate in economically disadvantaged areas, the relationship between median income and crime is far from straightforward—and some of our findings challenge these well-worn assumptions. The stereotype that low median areas experience higher crime rates is overly simplistic. While violent crimes show some correlation with lower-income neighborhoods, broader crime patterns reveal that income alone does not explain crime rates. Our analysis uncovers complexities and outliers that challenge conventional beliefs. 

The idea that crime is concentrated solely in low-income areas is pervasive but overly simplistic. While economically disadvantaged neighborhoods often face greater crime challenges, wealthier areas aren’t immune. 

```{r heatmap for crime count}
#| echo: false
#| warning: false

neighborhoods_lapd <- st_intersection(neighborhoods, lapd_boundary)


neighborhoods_lapd <- st_buffer(neighborhoods, dist = 0) %>%
  st_intersection(st_buffer(lapd_boundary, dist = 0))


crime_sf <- st_as_sf(data, coords = c("LON", "LAT"), crs = 4326)  # Crime data as sf object

# Filter crimes to those within LAPD boundary
crimes_in_lapd <- st_filter(crime_sf, lapd_boundary)

neighborhoods_lapd <- st_make_valid(neighborhoods_lapd)
crimes_in_lapd <- st_make_valid(crimes_in_lapd)

# Join crimes to neighborhoods
crimes_by_neighborhood <- st_join(crimes_in_lapd, neighborhoods_lapd, join = st_within)


# Ensure crimes_by_neighborhood includes counts and neighborhood polygons
crime_summary <- neighborhoods_lapd %>%
  left_join(
    crimes_by_neighborhood %>%
      st_drop_geometry() %>%  # Drop point geometry to focus on attributes
      group_by(name) %>%      # Replace "NAME" with neighborhood column in neighborhoods_lapd
      summarize(total_crimes = n()),
    by = "name"               # Join by neighborhood name or another matching column
  )


ggplot() +
  geom_sf(data = neighborhoods_lapd, fill = NA, color = "black") +  # Neighborhood outlines
  geom_sf(data = crime_summary, aes(fill = total_crimes), color = NA) +
  scale_fill_distiller(
    palette = "YlOrRd", 
    direction = 1, 
    na.value = "grey50",
    name = "Total Crimes"
  ) +
  labs(
    title = "Heatmap of Crimes by Neighborhood (LAPD Jurisdiction)",
    fill = "Total Crimes"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10)
  )

```
This heatmap visualizes the total crime distribution across Los Angeles neighborhoods under LAPD jurisdiction.  Darker areas indicate lower crime counts, while lighter areas signify higher crime activity. At a glance, the map reveals significant disparities in crime concentration across the city. High counts of crime are apparent in neighborhoods in Central and West where those neighborhoods are darker than the rest of the neighborhoods in Los Angeles.

However, this heatmap only shows the total crime counts geographically, without considering the underlying economic conditions of each neighborhood. By incorporating median income into the data and visualizations, we can better understand the relationship between crime and median income.

```{r relationship between crime and income}
#| echo: false
crime_with_income <- st_join(crime_with_neighborhoods, economic_data, join = st_within)
median_income_by_neighborhood <- crime_with_income %>%
  group_by(AREA.NAME) %>%
  summarize(
    median_income = median(estimate, na.rm = TRUE),
    total_crimes = n(),  # Optional: Include total crimes
    geometry = st_union(geometry)
  ) %>%
  filter(!is.na(median_income)) %>% 
  st_as_sf()
ggplot(median_income_by_neighborhood, aes(x = median_income, y = total_crimes)) +
  geom_point(aes(color = median_income), alpha = 0.7, size=4) +
  scale_color_viridis_c(option = "plasma", name = "Median Income") +
  labs(
    title = "Relationship Between Median Income and Total Crimes",
    x = "Median Income (USD)",
    y = "Total Crimes",
    caption = "Source: ACS 2020 and Crime Data"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```
This scatterplot shows the relationship between median income and total crimes across neighborhoods in Los Angeles. Each point represents a neighborhood, with the x-axis showing median income and the y-axis showing the total number of crimes. The colors range from dark purple to bright yellow, indicating neighborhoods with lower to higher median incomes, respectively.

At first look, the graph reveals no clear or consistent correlation between median income and total crime levels. While some low-income neighborhoods (darker points) experience higher crime rates, several high-income neighborhoods (yellow points) also show significant crime activity.

This pattern underscores that the relationship between income and crime is not straightforward. Factors beyond income, such as population density, local policies, or social dynamics, likely play a significant role in shaping crime rates. This finding challenges traditional stereotypes and invites a deeper examination of what drives crime in Los Angeles communities.

```{r violent crime in each neighborhood}
#| echo: false

crime_with_income <- crime_with_income %>%
  mutate(
    crime_type = case_when(
      str_detect(Crm.Cd.Desc, regex("Burglary|Theft|Shoplifting|Robbery|Vandalism|Stolen", ignore_case = TRUE)) ~ "Property Crime",
      str_detect(Crm.Cd.Desc, "ASSAULT|ROBBERY|HOMICIDE|KIDNAPPING|SEXUAL ASSAULT") ~ "Violent Crime",
      TRUE ~ "Other"
    )
  )
property_crime_summary <- crime_with_income %>%
  filter(crime_type == "Violent Crime") %>%  # Filter for property crimes
  group_by(AREA.NAME) %>%  # Group by neighborhood
  summarize(
    median_income = median(estimate, na.rm = TRUE),  # Median income per neighborhood
    property_crimes = n()  # Count the number of property crimes
  ) %>%
  arrange(median_income) %>%  # Order neighborhoods by median income
  mutate(AREA.NAME = factor(AREA.NAME, levels = AREA.NAME))  # Convert to factor to preserve order

# Plot the data
ggplot(property_crime_summary, aes(x = AREA.NAME, y = property_crimes)) +
  geom_bar(stat = "identity", aes(fill = median_income), show.legend = TRUE) +
  scale_fill_viridis_c(option = "plasma", name = "Median Income") +
  labs(
    title = "Violent
    Crimes vs Median Income by Neighborhood",
    x = "Neighborhood (Ordered by Median Income)",
    y = "Number of Violent Crimes",
    caption = "Source: ACS 2020 and Crime Data"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10)),
    plot.title = element_text(hjust = 0.5)
  )

```
However, when we shift focus from total crime counts to violent crimes and sort neighborhoods by median income, a more structured trend emerges. The bar chart highlights that neighborhoods with lower median incomes—such as Newton and Rampart consistently report the highest levels of violent crime. In contrast, wealthier areas like West LA and Devonshire show significantly fewer violent incidents.This displays a clear negative correlation between median income and violent crime rates. Neighborhoods with lower median incomes tend to experience higher levels of violent crime, while neighborhoods with higher median incomes report fewer violent crimes. 

There is a glaring outlier of Central LA facing high crime counts despite being on the higher median income relative to the other Los Angeles Neighborhood which doesn't fit with the correlation between median income and violent crime. However, this only devles into a certain category of crime. Crime in Los Angeles is a multifaceted issue. Our analysis challenges the simplistic narrative linking poverty and crime, showing that even wealthy neighborhoods can face significant crime challenges. 
While focusing on violent crimes reveals a clear negative correlation with median income, examining crime relative to neighborhood populations adds another layer of complexity. Being in more dense-populated neighborhoods may contribute to more crime which scaling the crime count in proportion to population give a more accurate look into the relationship with median income and crime.

```{r Ratio Graph}
#| echo: false

library(ggplot2)
library(dplyr)

# Filter for 2024 data, remove NA values, and calculate crime-to-population ratio
crime_population_2024 <- crime_population_summary %>%
  filter(year == 2024) %>%
  mutate(crime_to_population_ratio = ifelse(total_population > 0, crime_count / total_population, NA)) %>%
  filter(!is.na(crime_to_population_ratio) & !is.na(`AREA NAME`))  # Remove rows with NA in crime ratio or area name

# Plot the crime-to-population ratio per area for 2024
ggplot(crime_population_2024, aes(x = reorder(`AREA NAME`, crime_to_population_ratio), y = crime_to_population_ratio)) +
  geom_bar(stat = "identity", fill = "blue") +  # Set the bar color to blue
  coord_flip() +  # Flip the axes
  labs(
    title = "Crime-to-Population Ratio per Area (2024)",
    x = "Neighborhood",
    y = "Crime-to-Population Ratio"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 8))  # Adjust text size for readability

```

Areas like 77th Street, Southwest, and Southeast stand out with significantly higher crime-to-population ratios, indicating that residents in these neighborhoods experience crime at a much higher rate compared to others. This metric underscores the unequal distribution of crime intensity across Los Angeles, revealing how population size can amplify the impact of crime on communities. Most of the neighborhoods that stand out with significantly high crime-to-population ratios all fall on the lower end of the median income. 

The relationship between median income and crime in Los Angeles is far from straightforward. While there is a noticeable negative correlation—lower median income neighborhoods often experience higher crime rates—this relationship becomes less clear when accounting for factors like population density and proportional impacts. Population size, density, and local factors significantly shape crime distribution across neighborhoods. A simple link between poverty and crime oversimplifies a complex issue. Addressing crime in Los Angeles requires considering economic conditions, community dynamics, and residents' lived experiences.

---


### Interactive

You will also be required to make an interactive dashboard like [this one](/flex/flex.html).

Your Big Data page should also include a small interactive dashboard. The dashboard should be created either using Shinylive, as below. This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.





---

## Rubric: On this page

You will

* Title
  * Your big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.
* Clarity of Explanation
  * You should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don't go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.
  * Each figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.
* Creativity
  * Do your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.
* Interactive component
  * Quality and ease of use of the interactive components.
Is it clear what can be explored using your interactive components?
Does it enhance and reinforce your conclusions?
* This page should be self-contained.
  
**Note**: This page should have no code visible, i.e. use `#| echo: FALSE`.  




## Rubric: Other components

### Video Recording

Make a video recording (probably using Zoom) demonstrating your interactive components.
You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA.
This video should be no longer than 4 minutes.
Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website.
This can be presented by any subset of the team members.


### Rest of the Site

Finally, here are important things to keep in mind for the rest of the site. 

The main title of your page is informative.
Each post has an author/description/informative title.
All lab required posts are present.
Each page (including the home page) has a nice featured image associated with it.
Your about page is up to date and clean.
You have removed the generic posts from the initial site template.

---


### Interactive

You will also be required to make an interactive dashboard like [this one](/flex/flex.html).

Your Big Data page should also include a small interactive dashboard. The dashboard should be created either using Shinylive, as below. This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.





---

## Rubric: On this page

You will

* Title
  * Your big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.
* Clarity of Explanation
  * You should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don't go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.
  * Each figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.
* Creativity
  * Do your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.
* Interactive component
  * Quality and ease of use of the interactive components.
Is it clear what can be explored using your interactive components?
Does it enhance and reinforce your conclusions?
* This page should be self-contained.
  
**Note**: This page should have no code visible, i.e. use `#| echo: FALSE`.  




## Rubric: Other components

### Video Recording

Make a video recording (probably using Zoom) demonstrating your interactive components.
You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA.
This video should be no longer than 4 minutes.
Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website.
This can be presented by any subset of the team members.


### Rest of the Site

Finally, here are important things to keep in mind for the rest of the site. 

The main title of your page is informative.
Each post has an author/description/informative title.
All lab required posts are present.
Each page (including the home page) has a nice featured image associated with it.
Your about page is up to date and clean.
You have removed the generic posts from the initial site template.
